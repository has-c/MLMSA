{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pyopenms\r\n",
    "from pyopenms import *\r\n",
    "from scipy.spatial.distance import euclidean\r\n",
    "from operator import itemgetter\r\n",
    "import pandas as pd\r\n",
    "from binding_sites_helper import sum_spectra, get_difference, find_closest\r\n",
    "from os import listdir\r\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "input_data_url = 'Data//CSV Data//'\r\n",
    "input_files = sorted(listdir(input_data_url))\r\n",
    "input_files = [file for file in input_files if file not in ['.DS_Store', 'demo_4.csv']]\r\n",
    "\r\n",
    "#unbound/bound files\r\n",
    "unbound_pattern = re.compile(\"u\")\r\n",
    "unbound_file_matches = [file for file in input_files if unbound_pattern.match(file)] \r\n",
    "bound_file_matches = [file for file in input_files if file not in unbound_file_matches]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "for unbound_file in unbound_file_matches:\r\n",
    "    for bound_file in bound_file_matches:\r\n",
    "\r\n",
    "        print(unbound_file)\r\n",
    "        print(bound_file)\r\n",
    "\r\n",
    "        #read in the files\r\n",
    "        bound_df = pd.read_csv(input_data_url + bound_file)\r\n",
    "        unbound_df = pd.read_csv(input_data_url + unbound_file)\r\n",
    "\r\n",
    "        #extract bound and unbound m/z and intensity\r\n",
    "        bound_mz = list(bound_df['m/z'].values)\r\n",
    "        bound_intensity = list(bound_df['intensity'].values)\r\n",
    "        unbound_mz = list(unbound_df['m/z'].values)\r\n",
    "        unbound_intensity = list(unbound_df['intensity'].values)\r\n",
    "\r\n",
    "        #Create experiments\r\n",
    "        bound_exp = pyopenms.MSExperiment()\r\n",
    "        bound_spectrum = MSSpectrum()\r\n",
    "        unbound_exp = pyopenms.MSExperiment()\r\n",
    "        unbound_spectrum = MSSpectrum()\r\n",
    "\r\n",
    "        #Update the experiment with the bound or unbound data, then store it in a file\r\n",
    "        unbound_spectrum.set_peaks([unbound_mz, unbound_intensity])\r\n",
    "        unbound_exp.setSpectra([unbound_spectrum])\r\n",
    "        pyopenms.MzMLFile().store(\"unbound.mzML\", unbound_exp)\r\n",
    "        bound_spectrum.set_peaks([bound_mz, bound_intensity])\r\n",
    "        bound_exp.setSpectra([bound_spectrum])\r\n",
    "        pyopenms.MzMLFile().store(\"bound.mzML\", bound_exp)\r\n",
    "\r\n",
    "        #Import the two mzML files into experiments, and retrieve a single spectrum for each\r\n",
    "        bound = MSExperiment()\r\n",
    "        MzMLFile().load(\"bound.mzML\", bound)\r\n",
    "        bound_spectrum = sum_spectra(bound.getSpectra())\r\n",
    "        unbound = MSExperiment()\r\n",
    "        MzMLFile().load(\"unbound.mzML\", unbound)\r\n",
    "        unbound_spectrum = sum_spectra(unbound.getSpectra())\r\n",
    "\r\n",
    "        #In theory, subtracting the unbound spectrum from the bound spectrum should return the effects of the binding with the platin\r\n",
    "        binding_effect = get_difference(bound_spectrum, unbound_spectrum)\r\n",
    "\r\n",
    "        #Theoretical Ub Spectrum\r\n",
    "        #Convert the string representation of Ubiquitin into an amino acid sequence object\r\n",
    "        ubiquitin = AASequence.fromString(\"MQIFVKTLTGKTITLEVEPSDTIENVKAKIQDKEGIPPDQQRLIFAGKQLEDGRTLSDYNIQKESTLHLVLRLRGG\")\r\n",
    "        tsg = TheoreticalSpectrumGenerator()\r\n",
    "        spectrum = MSSpectrum()\r\n",
    "        #Initialise parameters object and set the values for parameters\r\n",
    "        #To change which parameters are set to true (false is default), specific lines can be commented out and vice versa\r\n",
    "        parameters = Param()\r\n",
    "        parameters.setValue(b\"add_isotopes\", b\"true\", \"\")\r\n",
    "        #parameters.setValue(b\"add_losses\", b\"true\", \"\")\r\n",
    "        parameters.setValue(b\"add_b_ions\", b\"true\", \"\")\r\n",
    "        parameters.setValue(b\"add_y_ions\", b\"true\", \"\")\r\n",
    "        parameters.setValue(b\"add_a_ions\", b\"true\", \"\")\r\n",
    "        parameters.setValue(b\"add_c_ions\", b\"true\", \"\")\r\n",
    "        parameters.setValue(b\"add_x_ions\", b\"true\", \"\")\r\n",
    "        parameters.setValue(b\"add_z_ions\", b\"true\", \"\")\r\n",
    "        parameters.setValue(b\"add_metainfo\", b\"true\", \"\")\r\n",
    "        tsg.setParameters(parameters)\r\n",
    "        #Generate the theoretical spectrum of Ubiquitin\r\n",
    "        tsg.getSpectrum(spectrum, ubiquitin, 1, 2)\r\n",
    "\r\n",
    "        #Stores the peaks of the difference spectrum in a list of [m/z, i] items\r\n",
    "        difference = []\r\n",
    "        for mz, i in binding_effect.items():\r\n",
    "            if i < 0:\r\n",
    "                difference.append([mz,-i])\r\n",
    "\r\n",
    "        #The theoretical spectrum is converted from a pair of lists to a single list of [m/z, i] items\r\n",
    "        theoretical = []\r\n",
    "        for i in range(len(spectrum.get_peaks()[0])):\r\n",
    "            current_mz = spectrum.get_peaks()[0][i]\r\n",
    "            current_intensity = spectrum.get_peaks()[1][i]\r\n",
    "            theoretical.append([current_mz, current_intensity])\r\n",
    "\r\n",
    "\r\n",
    "        len_t = len(theoretical)\r\n",
    "        #Sort the difference spectrum by intensity values from largest to smallest\r\n",
    "        filtered_difference = sorted(difference, key=itemgetter(1), reverse=True)\r\n",
    "        #To make the DTW calculation less computationally intensive, only the n peaks with the highest intensity values are used (where n is the number of peaks in the theoretical spectrum)\r\n",
    "        if len_t < len(filtered_difference):\r\n",
    "            filtered_difference = filtered_difference[:len_t]\r\n",
    "        len_fd = len(filtered_difference)\r\n",
    "\r\n",
    "        #The number of peaks was further reduced such that only peaks with large enough intensities were considered as meaningful indicaitons of binding sites\r\n",
    "        significant_peaks = filtered_difference[:100]\r\n",
    "\r\n",
    "        #Create a list of pairs of peaks matching each peak from significant_peaks to it's closest counterpart in the theoretical spectrum\r\n",
    "        matched_peaks = []\r\n",
    "        for peak in significant_peaks:\r\n",
    "            theo_peak = find_closest(peak, theoretical)\r\n",
    "            matched_peaks.append([peak, theo_peak])\r\n",
    "\r\n",
    "        #For each pair of matched peaks, their m/z and intensity is added to a dictionary\r\n",
    "        matching_significance = {}\r\n",
    "        for match in matched_peaks:\r\n",
    "            match_mz = match[1][0]\r\n",
    "            match_i = match[0][1]\r\n",
    "            #Multiple signigicant peaks may be matched to the same theoretical peak if that theoretical peak is the closest peak to multiple experimental peaks, in which case their intensities are added together\r\n",
    "            #These sums of intensities are reffered to as the 'significance' of the theoretical peak which was matched\r\n",
    "            if match_mz not in matching_significance.keys():\r\n",
    "                matching_significance[match_mz] = match_i\r\n",
    "            else:\r\n",
    "                matching_significance[match_mz] += match_i\r\n",
    "\r\n",
    "            #For each peak identified in the matching_significance above, the ion of that peak is identified from the original TheoreticalSpectrumGenerator spectrum\r\n",
    "            fragments = []\r\n",
    "            for ion, peak in zip(spectrum.getStringDataArrays()[0], spectrum):\r\n",
    "                for peak_mz, peak_sig in matching_significance.items():\r\n",
    "                    if peak.getMZ() == peak_mz:\r\n",
    "                        fragments.append([ion, peak_mz, peak_sig])\r\n",
    "            #These fragments (which represent potential binding sites) are sorted from most significant to least\r\n",
    "            fragments = sorted(fragments, key=itemgetter(2), reverse=True)\r\n",
    "\r\n",
    "            #Results of potential binding sites\r\n",
    "            #fragment type, location, and charge (e.g. y15++), the m/z of that fragment, and the fragments significance as a potential binding site\r\n",
    "            ion_list = [fragment[0] for fragment in fragments]\r\n",
    "            mass_charge_list = [fragment[1] for fragment in fragments]\r\n",
    "            relative_significance = [fragment[2] for fragment in fragments]\r\n",
    "\r\n",
    "            filename_out = unbound_file.split(\".csv\")[0] + \"-\" + bound_file.split(\".csv\")[0] + \".xlsx\"\r\n",
    "            results_df = pd.DataFrame({'Ion':ion_list, 'm/z':mass_charge_list, 'Relative Significance': relative_significance})\r\n",
    "            results_df.to_excel(filename_out, index=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ub_1.csv\n",
      "c_1.csv\n",
      "ub_1.csv\n",
      "c_10.csv\n",
      "ub_1.csv\n",
      "c_11.csv\n",
      "ub_1.csv\n",
      "c_12.csv\n",
      "ub_1.csv\n",
      "c_13.csv\n",
      "ub_1.csv\n",
      "c_14.csv\n",
      "ub_1.csv\n",
      "c_15.csv\n",
      "ub_1.csv\n",
      "c_16.csv\n",
      "ub_1.csv\n",
      "c_17.csv\n",
      "ub_1.csv\n",
      "c_18.csv\n",
      "ub_1.csv\n",
      "c_19.csv\n",
      "ub_1.csv\n",
      "c_2.csv\n",
      "ub_1.csv\n",
      "c_3.csv\n",
      "ub_1.csv\n",
      "c_4.csv\n",
      "ub_1.csv\n",
      "c_5.csv\n",
      "ub_1.csv\n",
      "c_6.csv\n",
      "ub_1.csv\n",
      "c_7.csv\n",
      "ub_1.csv\n",
      "c_8.csv\n",
      "ub_1.csv\n",
      "c_9.csv\n",
      "ub_1.csv\n",
      "o_1.csv\n",
      "ub_1.csv\n",
      "o_2.csv\n",
      "ub_1.csv\n",
      "o_3.csv\n",
      "ub_1.csv\n",
      "o_4.csv\n",
      "ub_1.csv\n",
      "o_5.csv\n",
      "ub_1.csv\n",
      "o_6.csv\n",
      "ub_1.csv\n",
      "t_1.csv\n",
      "ub_1.csv\n",
      "t_2.csv\n",
      "ub_1.csv\n",
      "t_3.csv\n",
      "ub_1.csv\n",
      "t_4.csv\n",
      "ub_1.csv\n",
      "t_5.csv\n",
      "ub_2.csv\n",
      "c_1.csv\n",
      "ub_2.csv\n",
      "c_10.csv\n",
      "ub_2.csv\n",
      "c_11.csv\n",
      "ub_2.csv\n",
      "c_12.csv\n",
      "ub_2.csv\n",
      "c_13.csv\n",
      "ub_2.csv\n",
      "c_14.csv\n",
      "ub_2.csv\n",
      "c_15.csv\n",
      "ub_2.csv\n",
      "c_16.csv\n",
      "ub_2.csv\n",
      "c_17.csv\n",
      "ub_2.csv\n",
      "c_18.csv\n",
      "ub_2.csv\n",
      "c_19.csv\n",
      "ub_2.csv\n",
      "c_2.csv\n",
      "ub_2.csv\n",
      "c_3.csv\n",
      "ub_2.csv\n",
      "c_4.csv\n",
      "ub_2.csv\n",
      "c_5.csv\n",
      "ub_2.csv\n",
      "c_6.csv\n",
      "ub_2.csv\n",
      "c_7.csv\n",
      "ub_2.csv\n",
      "c_8.csv\n",
      "ub_2.csv\n",
      "c_9.csv\n",
      "ub_2.csv\n",
      "o_1.csv\n",
      "ub_2.csv\n",
      "o_2.csv\n",
      "ub_2.csv\n",
      "o_3.csv\n",
      "ub_2.csv\n",
      "o_4.csv\n",
      "ub_2.csv\n",
      "o_5.csv\n",
      "ub_2.csv\n",
      "o_6.csv\n",
      "ub_2.csv\n",
      "t_1.csv\n",
      "ub_2.csv\n",
      "t_2.csv\n",
      "ub_2.csv\n",
      "t_3.csv\n",
      "ub_2.csv\n",
      "t_4.csv\n",
      "ub_2.csv\n",
      "t_5.csv\n",
      "ub_3.csv\n",
      "c_1.csv\n",
      "ub_3.csv\n",
      "c_10.csv\n",
      "ub_3.csv\n",
      "c_11.csv\n",
      "ub_3.csv\n",
      "c_12.csv\n",
      "ub_3.csv\n",
      "c_13.csv\n",
      "ub_3.csv\n",
      "c_14.csv\n",
      "ub_3.csv\n",
      "c_15.csv\n",
      "ub_3.csv\n",
      "c_16.csv\n",
      "ub_3.csv\n",
      "c_17.csv\n",
      "ub_3.csv\n",
      "c_18.csv\n",
      "ub_3.csv\n",
      "c_19.csv\n",
      "ub_3.csv\n",
      "c_2.csv\n",
      "ub_3.csv\n",
      "c_3.csv\n",
      "ub_3.csv\n",
      "c_4.csv\n",
      "ub_3.csv\n",
      "c_5.csv\n",
      "ub_3.csv\n",
      "c_6.csv\n",
      "ub_3.csv\n",
      "c_7.csv\n",
      "ub_3.csv\n",
      "c_8.csv\n",
      "ub_3.csv\n",
      "c_9.csv\n",
      "ub_3.csv\n",
      "o_1.csv\n",
      "ub_3.csv\n",
      "o_2.csv\n",
      "ub_3.csv\n",
      "o_3.csv\n",
      "ub_3.csv\n",
      "o_4.csv\n",
      "ub_3.csv\n",
      "o_5.csv\n",
      "ub_3.csv\n",
      "o_6.csv\n",
      "ub_3.csv\n",
      "t_1.csv\n",
      "ub_3.csv\n",
      "t_2.csv\n",
      "ub_3.csv\n",
      "t_3.csv\n",
      "ub_3.csv\n",
      "t_4.csv\n",
      "ub_3.csv\n",
      "t_5.csv\n",
      "ub_4.csv\n",
      "c_1.csv\n",
      "ub_4.csv\n",
      "c_10.csv\n",
      "ub_4.csv\n",
      "c_11.csv\n",
      "ub_4.csv\n",
      "c_12.csv\n",
      "ub_4.csv\n",
      "c_13.csv\n",
      "ub_4.csv\n",
      "c_14.csv\n",
      "ub_4.csv\n",
      "c_15.csv\n",
      "ub_4.csv\n",
      "c_16.csv\n",
      "ub_4.csv\n",
      "c_17.csv\n",
      "ub_4.csv\n",
      "c_18.csv\n",
      "ub_4.csv\n",
      "c_19.csv\n",
      "ub_4.csv\n",
      "c_2.csv\n",
      "ub_4.csv\n",
      "c_3.csv\n",
      "ub_4.csv\n",
      "c_4.csv\n",
      "ub_4.csv\n",
      "c_5.csv\n",
      "ub_4.csv\n",
      "c_6.csv\n",
      "ub_4.csv\n",
      "c_7.csv\n",
      "ub_4.csv\n",
      "c_8.csv\n",
      "ub_4.csv\n",
      "c_9.csv\n",
      "ub_4.csv\n",
      "o_1.csv\n",
      "ub_4.csv\n",
      "o_2.csv\n",
      "ub_4.csv\n",
      "o_3.csv\n",
      "ub_4.csv\n",
      "o_4.csv\n",
      "ub_4.csv\n",
      "o_5.csv\n",
      "ub_4.csv\n",
      "o_6.csv\n",
      "ub_4.csv\n",
      "t_1.csv\n",
      "ub_4.csv\n",
      "t_2.csv\n",
      "ub_4.csv\n",
      "t_3.csv\n",
      "ub_4.csv\n",
      "t_4.csv\n",
      "ub_4.csv\n",
      "t_5.csv\n",
      "ub_5.csv\n",
      "c_1.csv\n",
      "ub_5.csv\n",
      "c_10.csv\n",
      "ub_5.csv\n",
      "c_11.csv\n",
      "ub_5.csv\n",
      "c_12.csv\n",
      "ub_5.csv\n",
      "c_13.csv\n",
      "ub_5.csv\n",
      "c_14.csv\n",
      "ub_5.csv\n",
      "c_15.csv\n",
      "ub_5.csv\n",
      "c_16.csv\n",
      "ub_5.csv\n",
      "c_17.csv\n",
      "ub_5.csv\n",
      "c_18.csv\n",
      "ub_5.csv\n",
      "c_19.csv\n",
      "ub_5.csv\n",
      "c_2.csv\n",
      "ub_5.csv\n",
      "c_3.csv\n",
      "ub_5.csv\n",
      "c_4.csv\n",
      "ub_5.csv\n",
      "c_5.csv\n",
      "ub_5.csv\n",
      "c_6.csv\n",
      "ub_5.csv\n",
      "c_7.csv\n",
      "ub_5.csv\n",
      "c_8.csv\n",
      "ub_5.csv\n",
      "c_9.csv\n",
      "ub_5.csv\n",
      "o_1.csv\n",
      "ub_5.csv\n",
      "o_2.csv\n",
      "ub_5.csv\n",
      "o_3.csv\n",
      "ub_5.csv\n",
      "o_4.csv\n",
      "ub_5.csv\n",
      "o_5.csv\n",
      "ub_5.csv\n",
      "o_6.csv\n",
      "ub_5.csv\n",
      "t_1.csv\n",
      "ub_5.csv\n",
      "t_2.csv\n",
      "ub_5.csv\n",
      "t_3.csv\n",
      "ub_5.csv\n",
      "t_4.csv\n",
      "ub_5.csv\n",
      "t_5.csv\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}