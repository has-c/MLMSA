{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert XY to CSV - Combine seperate spectrums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xy_file(file_url):\n",
    "    #Open the file with the spectra and read the contents\n",
    "    input_df = pd.read_table(file_url, delimiter=\" \", header=None, names=['m/z', 'intensity'])\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_url = 'Data//XY Data//'\n",
    "output_data_url = 'Data//CSV Data//'\n",
    "final_data_url = 'Data//Final CSV Data//'\n",
    "\n",
    "input_files = sorted(listdir(input_data_url))\n",
    "input_files = [file for file in input_files if file != '.DS_Store']\n",
    "\n",
    "output_files = sorted(listdir(output_data_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_1.xy\n",
      "c_10.xy\n",
      "c_11.xy\n",
      "c_12.xy\n",
      "c_13.xy\n",
      "c_14_1.xy\n",
      "c_14_2.xy\n",
      "c_15_1.xy\n",
      "c_15_2.xy\n",
      "c_16_1.xy\n",
      "c_16_2.xy\n",
      "c_16_3.xy\n",
      "c_17.xy\n",
      "c_18_1.xy\n",
      "c_18_2.xy\n",
      "c_19_1.xy\n",
      "c_19_2.xy\n",
      "c_19_3.xy\n",
      "c_2.xy\n",
      "c_3_1.xy\n",
      "c_3_2.xy\n",
      "c_4.xy\n",
      "c_5_1.xy\n",
      "c_5_2.xy\n",
      "c_5_3.xy\n",
      "c_6_1.xy\n",
      "c_6_2.xy\n",
      "c_6_3.xy\n",
      "c_7.xy\n",
      "c_8_1.xy\n",
      "c_8_2.xy\n",
      "c_9.xy\n",
      "demo_4.xy\n",
      "o_1_1.xy\n",
      "o_1_2.xy\n",
      "o_1_3.xy\n",
      "o_2.xy\n",
      "o_3_1.xy\n",
      "o_3_2.xy\n",
      "o_4.xy\n",
      "o_5_1.xy\n",
      "o_5_2.xy\n",
      "o_5_3.xy\n",
      "o_6.xy\n",
      "t_1_1.xy\n",
      "t_1_2.xy\n",
      "t_1_3.xy\n",
      "t_1_4.xy\n",
      "t_2.xy\n",
      "t_3.xy\n",
      "t_4_1.xy\n",
      "t_4_2.xy\n",
      "t_5_1.xy\n",
      "t_5_2.xy\n",
      "ub_1_1.xy\n",
      "ub_1_2.xy\n",
      "ub_2.xy\n",
      "ub_3.xy\n",
      "ub_4_1.xy\n",
      "ub_4_2.xy\n",
      "ub_5_1.xy\n",
      "ub_5_2.xy\n"
     ]
    }
   ],
   "source": [
    "#concatenate different spectrums \n",
    "processed_files = []\n",
    "for file in input_files: \n",
    "    print(file)\n",
    "\n",
    "    #check whether spectrum has been processed\n",
    "    if file not in processed_files: \n",
    "\n",
    "        #assess if the spectrum is split into multiple files\n",
    "        #if name contains more than 1 underscore then yes it is split\n",
    "        file_name_split = file.split(\"_\")\n",
    "        split_spectrum = len(file_name_split) > 2\n",
    "        \n",
    "\n",
    "        if split_spectrum:\n",
    "            #find the other files with the same name and process them \n",
    "            pattern = re.compile(\"^\"+file_name_split[0]+\"_\"+file_name_split[1])\n",
    "            matches = [file for file in input_files if pattern.match(file)]\n",
    "            \n",
    "            #load matched spectrums, concatenate together and write out\n",
    "            input_df = pd.DataFrame([])\n",
    "            for file in matches:\n",
    "                if input_df.size == 0:\n",
    "                    input_df = read_xy_file(input_data_url+file)\n",
    "                else: \n",
    "                    df = read_xy_file(input_data_url+file)\n",
    "                    input_df = pd.concat([input_df, df], ignore_index=True)\n",
    "                    \n",
    "                #file has been processed\n",
    "                processed_files.append(file)\n",
    "            \n",
    "            #write out entire spectrum\n",
    "            output_filename = file_name_split[0] + \"_\" + file_name_split[1] + \".csv\"\n",
    "            input_df.to_csv(output_data_url+ output_filename, index=False)\n",
    "\n",
    "        else:\n",
    "            output_filename = file_name_split[0] + \"_\" + file_name_split[1].split(\".\")[0] + \".csv\"\n",
    "\n",
    "            #spectrum is not split so just save it as a csv\n",
    "            input_df = read_xy_file(input_data_url+file)\n",
    "            input_df.to_csv(output_data_url+ output_filename, index=False)\n",
    "\n",
    "            #add file to processed files\n",
    "            processed_files.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine M/Z, intensity pairs that are the same just seperated by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_1.csv\n",
      "c_10.csv\n",
      "c_11.csv\n",
      "c_12.csv\n",
      "c_13.csv\n",
      "c_14.csv\n",
      "c_15.csv\n",
      "c_16.csv\n",
      "c_17.csv\n",
      "c_18.csv\n",
      "c_19.csv\n",
      "c_2.csv\n",
      "c_3.csv\n",
      "c_4.csv\n",
      "c_5.csv\n",
      "c_6.csv\n",
      "c_7.csv\n",
      "c_8.csv\n",
      "c_9.csv\n",
      "demo_4.csv\n",
      "o_1.csv\n",
      "o_2.csv\n",
      "o_3.csv\n",
      "o_4.csv\n",
      "o_5.csv\n",
      "o_6.csv\n",
      "t_1.csv\n",
      "t_2.csv\n",
      "t_3.csv\n",
      "t_4.csv\n",
      "t_5.csv\n",
      "ub_1.csv\n",
      "ub_2.csv\n",
      "ub_3.csv\n",
      "ub_4.csv\n",
      "ub_5.csv\n"
     ]
    }
   ],
   "source": [
    "for file in output_files: \n",
    "    print(file)\n",
    "    \n",
    "    intensity = list()\n",
    "    df = pd.read_csv(output_data_url + file)\n",
    "    \n",
    "    #calculate average intensity \n",
    "    unique_mz_values = pd.unique(df['m/z'])\n",
    "    for value in unique_mz_values:\n",
    "        avg_intensity = df[df['m/z'] == value]['intensity'].mean()\n",
    "        intensity.append(avg_intensity)   \n",
    "    \n",
    "    spec_df = pd.DataFrame({'m/z': unique_mz_values,\n",
    "                 'intensity':intensity})\n",
    "    \n",
    "    spec_df.to_csv(final_data_url+file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228038"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_mz_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980607"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
